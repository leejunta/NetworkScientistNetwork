sum(predict01[agree]==vowel.test$y[agree])/dim(vowel.test)[1]
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
set.seed(62433)
model01 <- train(diagnosis~.,data=training,method='rf')
model02 <- train(diagnosis~.,data=training,method='gbm')
model03 <- train(diagnosis~.,data=training,method='lda')
predict01 <- predict(model01,testing)
predict02 <- predict(model02,testing)
predict03 <- predict(model03,testing)
acc1 <- sum(predict01==testing$diagnosis)/dim(testing)[1]
acc2 <- sum(predict02==testing$diagnosis)/dim(testing)[1]
acc3 <- sum(predict03==testing$diagnosis)/dim(testing)[1]
acc1
acc2
acc3
stack <- data.frame(training$diagnosis,pred01,pred02,pred03)
pred01 <- predict(model01,training)
pred02 <- predict(model02,training)
pred03 <- predict(model03,training)
stack <- data.frame(training$diagnosis,pred01,pred02,pred03)
modelstack <- train(diagnosis~.,data=stack,method='rf')
stack
stack <- data.frame("diagnosis" = training$diagnosis,pred01,pred02,pred03)
modelstack <- train(diagnosis~.,data=stack,method='rf')
predict01 <- predict(modelstack,testing)
predictstack <- predict(modelstack,testing)
acc1 <- sum(predictstack==testing$diagnosis)/dim(testing)[1]
accstack <- sum(predictstack==testing$diagnosis)/dim(testing)[1]
accstack
predict01 <- predict(model01,testing)
predict02 <- predict(model02,testing)
predict03 <- predict(model03,testing)
acc1 <- sum(predict01==testing$diagnosis)/dim(testing)[1]
acc2 <- sum(predict02==testing$diagnosis)/dim(testing)[1]
acc3 <- sum(predict03==testing$diagnosis)/dim(testing)[1]
pred01 <- predict(model01,training)
pred02 <- predict(model02,training)
pred03 <- predict(model03,training)
stack <- data.frame("diagnosis" = training$diagnosis,pred01,pred02,pred03)
modelstack <- train(diagnosis~.,data=stack,method='rf')
predictstack <- predict(modelstack,testing)
modelstack
stack
dim(stakc)
dim(stack)
stack <- data.frame("diagnosis" = training$diagnosis,predict01,predict02,predict03)
stack <- data.frame("diagnosis" = testing$diagnosis,predict01,predict02,predict03)
modelstack <- train(diagnosis~.,data=stack,method='rf')
predictstack <- predict(modelstack,testing)
accstack <- sum(predictstack==testing$diagnosis)/dim(testing)[1]
accstack
acc1
acc2
acc3
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model01 <- train(CompressiveStrength~.,data=training,method='lasso')
model01 <- train(CompressiveStrength~.,data=training,method='lasso')
model01
model01$bestTune
model01$modelType
model01$results
model01$finalModel
model01$bestTune
model01$dots
model01$control
model01$preProcess
model01$resampledCM
model01$coefnames
?plot.enet
plot(model01)
plot(model01,plotType = 'level')
?plot.enet
plot(model01,xvar='step')
plot(model01)
model01$finalModel
model01$finalModel
plot(model01$finalModel)
plot(model01)
training
colnames(training)
plot(model01)
model01$finalModel
model01$coefnames
model01$xlevels
model01$terms
model01$levels
model01$times
model01$yLimits
model01$maximize
model01$resampledCM
model01$modelInfo
model01$results
model01$pred
model01$bestTune
model01$call
model01$finalModel
library(lubridate) # For year() function below
dat = read.csv("~/Downloads/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast",dependencies = T)
require(forecast)
tstrain
training
bats(tstrain)
model01 <- bats(tstrain)
predict(model01,testing)
model01 <- bats(training)
model01 <- bats(tstrain)
model01$lambda
model01$parameters
model01$fitted.values
plot(model01$fitted.values)
model01$errors
model01$errors+model01$fitted.values
model01$fitted.values-model01$errors
tstest = ts(testing$visitsTumblr)
predict(model01,tstest)
0 < 1 <3
0 < 1
(0<1) & (0<3)
(tstest < (model01$fitted.values+model01$errors))
tstest
tstrain
tstest
?bats
forecast(model01)
tstest
plot(tstest)
plot(model01)
plot(tstest)
forecast(tstest)
forecast(model01)
tstest
plot(tstest)
plot(forecast(model01))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
install.packages("e1071",dependencies = T)
install.packages("e1071", dependencies = T)
library(e1071)
model01<- svm(CompressiveStrength~.,data = training)
model01
predict(model01,testing)
predict.svm(model01,testing)
(predict(model01,testing)-testing$CompressiveStrength)^2/dim(testing)[1]
sum((predict(model01,testing)-testing$CompressiveStrength)^2)/dim(testing)[1]
predict(model01,testing)
testing$CompressiveStrength
length(testing$CompressiveStrength)
length(predict(model01,testing))
c(1,2,3)^2
sum(as.vector((predict(model01,testing))-as.vector(testing$CompressiveStrength))^2)/dim(testing)[1]
sqrt(sum(as.vector((predict(model01,testing))-as.vector(testing$CompressiveStrength))^2)/dim(testing)[1])
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model01 <- train(CompressiveStrength~.,data=training,method='lasso')
plot(model01)
coef(model01)
coef(model01)
coef(model01$finalModel)
require(glmnet)
install.packages("glmnet",dependencies = T)
require(glmnet)
x <- as.matrix(training[,-CompressiveStrength]) # Removes class
x <- as.matrix(training[,-"CompressiveStrength"]) # Removes class
training
training[,-"CompressiveStrength"]
colnames(training)
x <- as.matrix(training[,-9]) # Removes class
x
colnames(x)
y <- as.double(as.matrix(training[,-c(1:8)])) # Only class
set.seed(999)
cv.lasso <- cv.glmnet(x, y, family='binomial', alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')
x
levels(factor(x$flyash))
levels(factor(x$FlyAsh))
x
str(x)
x <- as.matrix(training[,-9]) # Removes class
levels(factor(as.data.frame(x)$FlyAsh))
cv.lasso <- cv.glmnet(x, y, family='binomial', alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')
y
cv.lasso <- cv.glmnet(x, y, alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')
plot(model01, xvar="lambda", label=TRUE)
?plot.enet
plot(model01,xvar = "step")
?plot.enet
plot(model01,xvar = "step",use.color = T)
?plot.enet
model01 <- train(CompressiveStrength~.,data=training,method='lasso')
model01
require(glmnet)
x <- training[,-9] # Removes class
y <- training[,-c(1:8)] # Only class
set.seed(999)
cv.lasso <- cv.glmnet(x, y, family='binomial', alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')
?cv.glmnet
cv.lasso <- cv.glmnet(x, y, alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')
y <- as.vector(training[,-c(1:8)]) # Only class
cv.lasso <- cv.glmnet(x, y, alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')
x <- as.matrix(training[,-9]) # Removes class
x
dim(x)
y <- as.vector(training[,-c(1:8)]) # Only class
dim(y)
length(y)
cv.lasso <- cv.glmnet(x, y, alpha=1)
plot(cv.lasso,xvar='lambda')
set.seed(233)
cv.lasso <- cv.glmnet(x, y, alpha=1)
set.seed(233)
cv.lasso <- cv.glmnet(x, y, alpha=1)
plot(mode01)
plot(model01)
model01 <- cv.glmnet(x, y, alpha=1)
plot(model01)
model01$glmnet.fit
model01$lambda.min
model01$lambda
model01
coef(model01)
plot(model01,xvar="lambda")
require(glmnet)
warnings()
install.packages("glmnet",dependencies = T)
install.packages("glmnet", dependencies = T)
require(glmnet)
plot(model01,xvar="lambda")
model01 <- cv.glmnet(x, y, alpha=1)
plot(model01,xvar="lambda")
model01 <- cv.glmnet(x, y, alpha=1)
plot(model01$glmnet.fit,xvar="lambda")
plot(model01$glmnet.fit,xvar="lambda",label =T)
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model01 <- train(diagnosis~.,data=training,method='rf')
model02 <- train(diagnosis~.,data=training,method='gbm')
model03 <- train(diagnosis~.,data=training,method='lda')
predict01 <- predict(model01,testing)
predict02 <- predict(model02,testing)
predict03 <- predict(model03,testing)
acc1 <- sum(predict01==testing$diagnosis)/dim(testing)[1]
acc2 <- sum(predict02==testing$diagnosis)/dim(testing)[1]
acc3 <- sum(predict03==testing$diagnosis)/dim(testing)[1]
acc1
acc2
acc3
pred01 <- predict(model01,training)
pred02 <- predict(model02,training)
pred03 <- predict(model03,training)
modelstack <- train(diagnosis~.,data=stack,method='rf')
predictstack <- predict(modelstack,testing)
accstack <- sum(predictstack==testing$diagnosis)/dim(testing)[1]
accstack
stack1 <- data.frame("diagnosis" = training$diagnosis,pred01,pred02,pred03)
stack1 <- data.frame("diagnosis" = training$diagnosis,pred01,pred02,pred03)
modelstack <- train(diagnosis~.,data=stack,method='rf')
predictstack <- predict(modelstack,testing)
accstack <- sum(predictstack==testing$diagnosis)/dim(testing)[1]
modelstack1 <- train(diagnosis~.,data=stack1,method='rf')
predictstack1 <- predict(modelstack1,testing)
accstack1 <- sum(predictstack1==testing$diagnosis)/dim(testing)[1]
stack1 <- data.frame("diagnosis" = training$diagnosis,pred01,pred02,pred03)
stack1
predictstack1 <- predict(modelstack1,testing)
modelstack1 <- train(diagnosis~.,data=stack1,method='rf')
modelstack1
predictstack1 <- predict(modelstack1,testing)
data(vowel.train)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model01 <- train(y~.,data=vowel.train,method='rf')
model02 <- train(y~.,data=vowel.train,method='gbm')
predict01 <- predict(model01,vowel.test)
predict02 <- predict(model02,vowel.test)
sum(predict01==vowel.test$y)/dim(vowel.test)[1]
sum(predict02==vowel.test$y)/dim(vowel.test)[1]
acc1 <- sum(predict01==testing$diagnosis)/dim(testing)[1]
acc2 <- sum(predict02==testing$diagnosis)/dim(testing)[1]
acc3 <- sum(predict03==testing$diagnosis)/dim(testing)[1]
model01 <- train(diagnosis~.,data=training,method='rf')
model02 <- train(diagnosis~.,data=training,method='gbm')
model03 <- train(diagnosis~.,data=training,method='lda')
predict01 <- predict(model01,testing)
predict02 <- predict(model02,testing)
predict03 <- predict(model03,testing)
acc1 <- sum(predict01==testing$diagnosis)/dim(testing)[1]
acc2 <- sum(predict02==testing$diagnosis)/dim(testing)[1]
acc3 <- sum(predict03==testing$diagnosis)/dim(testing)[1]
c(acc1,acc2,acc3)
shiny::runApp('Documents/Projects/SynonymRec/surveyThesaurus')
length(NULL)
length(NULL) > 0
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
sum(NULL)
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
a <- c("asdf","afsdf","vcxvd")
a
grepl('a',a)
a[grepl('a',a)]
a[grepl('a|v',a)]
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
a
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
shiny::runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
runApp('Documents/Projects/SynonymRec/surveyThesaurus')
library(fivethirtyeight)
gop
study_drugs
require(fivethirtyeight)
steak_survey
a <- asteak_survey
a <- steak_survey
consumption
alcohol-consumption
library(fivethirtyeight)
data(package = "fivethirtyeight")
counsin_marriage
cousin_marriage
drug_use
a <- drug_use
a
shiny::runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
length(network$links$value[network$links$source==x])+
length(network$links$value[network$links$target==x]))
centrality <- centrality/min(centrality)*10
centrality
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
length(network$links$value[network$links$source==x])+
length(network$links$value[network$links$target==x]))
centrality
min(centrality)
plot(centrality)
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
length(network$links$value[network$links$source==x])+
length(network$links$value[network$links$target==x]))
centrality <- (centrality+1)/min(centrality+1)*10
plot(centrality)
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
length(network$links$value[network$links$source==x])+
length(network$links$value[network$links$target==x]))
plot(centrality)
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
length(network$links$value[network$links$source==x])+
length(network$links$value[network$links$target==x]))
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
length(network$links$value[network$links$source==x])+
length(network$links$value[network$links$target==x]))
centrality <- (centrality+1)/min(centrality+1)+10
plot(centrality)
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
1/(sum(network$links$value[network$links$source==x])+
sum(network$links$value[network$links$target==x])))
centrality[which(is.infinite(centrality))] <- min(centrality)
centrality <- (centrality/min(centrality)+100)/10
plot(centrality)
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
1/(sum(network$links$value[network$links$source==x])+
sum(network$links$value[network$links$target==x])))
plot(centrality)
min(centrality)
centrality[which(is.infinite(centrality))] <- min(centrality)
plot(centrality)
centrality[which(is.infinite(centrality))] <- min(centrality)
plot(centrality)
centrality <- (centrality/min(centrality)+100)/10
plot(centrality)
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
1/(sum(network$links$value[network$links$source==x])+
sum(network$links$value[network$links$target==x])))
centrality[which(is.infinite(centrality))] <- min(centrality)
centrality <- (centrality/min(centrality)+150)/10
plot(centrality)
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
1/(sum(network$links$value[network$links$source==x])+
sum(network$links$value[network$links$target==x])))
centrality[which(is.infinite(centrality))] <- min(centrality)
centrality <- (centrality/min(centrality)+300)/10
plot(centrality)
centrality <- sapply(c(1:dim(network$nodes)[1]),
function(x)
1/(sum(network$links$value[network$links$source==x])+
sum(network$links$value[network$links$target==x])))
centrality[which(is.infinite(centrality))] <- min(centrality)
centrality <- (centrality/min(centrality))
plot(centrality)
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
centrality <- eigen(adjacency)
centrality <- log(centrality$vectors[,1]+10)
centrality <- (centrality/min(centrality))^500*10
plot(centrality)
centrality <- eigen(adjacency)
centrality <- log(centrality$vectors[,1]+10)
centrality <- (centrality/min(centrality))^200*10
plot(centrality)
centrality <- eigen(adjacency)
centrality <- log(centrality$vectors[,1]+10)
centrality <- (centrality/min(centrality))^180*10
plot(centrality)
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
runApp('Documents/Grinnell College/2016-2017/Spring/MAT397/Network/netsci/ScientistNetwork')
g<-read.graph("netscience/netscience.gml",format=c("gml"))
require(networkD3)
require(igraph)
require(plyr)
require(foreach)
require(WGCNA)
plot(g)
g<-read.graph("netscience/netscience.gml",format=c("gml"))
setwd("~/Documents/Projects/NetworkScientistNetwork")
